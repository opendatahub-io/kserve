# Copyright 2023 The KServe Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# coding: utf-8

"""
    KServe

    Python SDK for KServe  # noqa: E501

    The version of the OpenAPI document: v0.1
    Generated by: https://openapi-generator.tech
"""


from __future__ import absolute_import

import unittest
import datetime

import kserve
from kserve.models.v1alpha1_llm_inference_service_spec import (
    V1alpha1LLMInferenceServiceSpec,
)  # noqa: E501
from kserve.models.v1alpha1_extension import V1alpha1Extension  # noqa: E501
from kserve.models.v1alpha1_gie_inference_pool_spec import (
    V1alpha1GIEInferencePoolSpec,
)  # noqa: E501
from kserve.models.v1alpha1_gateway_routes_spec import (
    V1alpha1GatewayRoutesSpec,
)  # noqa: E501
from kserve.models.v1alpha1_gateway_spec import V1alpha1GatewaySpec  # noqa: E501
from kserve.models.v1alpha1_http_route_spec import V1alpha1HTTPRouteSpec  # noqa: E501
from kserve.models.v1alpha1_inference_pool_spec import (
    V1alpha1InferencePoolSpec,
)  # noqa: E501
from kserve.models.v1alpha1_ingress_spec import V1alpha1IngressSpec  # noqa: E501
from kserve.models.v1alpha1_llm_inference_service_spec import (
    V1alpha1LLMInferenceServiceSpec,
)  # noqa: E501
from kserve.models.v1alpha1_llm_model_spec import V1alpha1LLMModelSpec  # noqa: E501
from kserve.models.v1alpha1_lo_ra_spec import V1alpha1LoRASpec  # noqa: E501
from kserve.models.v1alpha1_parallelism_spec import (
    V1alpha1ParallelismSpec,
)  # noqa: E501
from kserve.models.v1alpha1_router_spec import V1alpha1RouterSpec  # noqa: E501
from kserve.models.v1alpha1_scheduler_spec import V1alpha1SchedulerSpec  # noqa: E501
from kserve.models.v1alpha1_untyped_object_reference import (
    V1alpha1UntypedObjectReference,
)  # noqa: E501
from kserve.models.v1alpha1_workload_spec import V1alpha1WorkloadSpec  # noqa: E501
from kserve.rest import ApiException


class TestV1alpha1LLMInferenceServiceSpec(unittest.TestCase):
    """V1alpha1LLMInferenceServiceSpec unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional):
        """Test V1alpha1LLMInferenceServiceSpec
        include_option is a boolean, when False only required
        params are included, when True both required and
        optional params are included"""
        # model = kserve.models.v1alpha1_llm_inference_service_spec.V1alpha1LLMInferenceServiceSpec()  # noqa: E501
        if include_optional:
            return V1alpha1LLMInferenceServiceSpec(
                base_refs=[None],
                model=V1alpha1LLMModelSpec(
                    criticality="0",
                    lora=V1alpha1LoRASpec(
                        adapters=[
                            V1alpha1LLMModelSpec(
                                criticality="0",
                                name="0",
                                uri="http://example.com/model",
                            )
                        ],
                    ),
                    name="0",
                    uri="http://example.com/model",
                ),
                parallelism=V1alpha1ParallelismSpec(
                    data=56,
                    data_local=56,
                    data_rpc_port=56,
                    expert=True,
                    pipeline=56,
                    tensor=56,
                ),
                prefill=V1alpha1WorkloadSpec(
                    parallelism=V1alpha1ParallelismSpec(
                        data=56,
                        data_local=56,
                        data_rpc_port=56,
                        expert=True,
                        pipeline=56,
                        tensor=56,
                    ),
                    replicas=56,
                    template=None,
                    worker=None,
                ),
                replicas=56,
                router=V1alpha1RouterSpec(
                    gateway=V1alpha1GatewaySpec(
                        refs=[
                            V1alpha1UntypedObjectReference(
                                name="0",
                                namespace="0",
                            )
                        ],
                    ),
                    ingress=V1alpha1IngressSpec(),
                    route=V1alpha1GatewayRoutesSpec(
                        http=V1alpha1HTTPRouteSpec(
                            spec=None,
                        ),
                    ),
                    scheduler=V1alpha1SchedulerSpec(
                        pool=V1alpha1InferencePoolSpec(
                            ref=None,
                            spec=V1alpha1GIEInferencePoolSpec(
                                extension_ref=V1alpha1Extension(
                                    failure_mode="0",
                                    group="0",
                                    kind="0",
                                    name="0",
                                    port_number=56,
                                ),
                                selector={"key": "0"},
                                target_port_number=56,
                            ),
                        ),
                        template=None,
                    ),
                ),
                template=None,
                worker=None,
            )
        else:
            return V1alpha1LLMInferenceServiceSpec()

    def testV1alpha1LLMInferenceServiceSpec(self):
        """Test V1alpha1LLMInferenceServiceSpec"""
        inst_req_only = self.make_instance(include_optional=False)
        inst_req_and_optional = self.make_instance(include_optional=True)


if __name__ == "__main__":
    unittest.main()
